{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ea768e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, optim\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c85fea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼파라미터\n",
    "EPOCH = 50\n",
    "BATCH_SIZE = 64\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "DEVICE = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
    "print(\"다음 기기로 학습합니다:\", DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64e3cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fashion MNIST 학습 데이터셋\n",
    "trainset = datasets.FashionMNIST(\n",
    "    root      = './.data/', \n",
    "    train     = True,\n",
    "    download  = True,\n",
    "    transform = transforms.ToTensor()\n",
    ")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset     = trainset,\n",
    "    batch_size  = BATCH_SIZE,\n",
    "    shuffle     = True,\n",
    "    num_workers = 2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767d0068",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        ## 입력 필요\n",
    "        pass\n",
    "\n",
    "    def forward(self, x):\n",
    "        ## 입력 필요\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2acfc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = Autoencoder().to(DEVICE)\n",
    "optimizer = torch.optim.Adam(autoencoder.parameters(), lr=0.005)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b277b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise(img):\n",
    "    noise = torch.randn(img.size()) * 0.2\n",
    "    noisy_img = img + noise\n",
    "    return noisy_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d43627",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(autoencoder, train_loader):\n",
    "        ## 입력 필요\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5386c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1, EPOCH+1):\n",
    "    loss = train(autoencoder, train_loader)\n",
    "    print(\"[Epoch {}] loss:{}\".format(epoch, loss))\n",
    "    # 이번 예제에선 학습시 시각화를 건너 뜁니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0443be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델이 학습시 본적이 없는 데이터로 검증하기 위해 테스트 데이터셋을 가져옵니다.\n",
    "testset = datasets.FashionMNIST(\n",
    "    root      = './.data/', \n",
    "    train     = False,\n",
    "    download  = True,\n",
    "    transform = transforms.ToTensor()\n",
    ")\n",
    "\n",
    "# 테스트셋에서 이미지 한장을 가져옵니다.\n",
    "sample_data = testset.data[0].view(-1, 28*28)\n",
    "sample_data = sample_data.type(torch.FloatTensor)/255.\n",
    "\n",
    "# 이미지를 add_noise로 오염시킨 후, 모델에 통과시킵니다.\n",
    "original_x = sample_data[0]\n",
    "noisy_x = add_noise(original_x).to(DEVICE)\n",
    "_, recovered_x = autoencoder(noisy_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344d0cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, a = plt.subplots(1, 3, figsize=(15, 15))\n",
    "\n",
    "# 시각화를 위해 넘파이 행렬로 바꿔줍니다.\n",
    "original_img = np.reshape(original_x.to(\"cpu\").data.numpy(), (28, 28))\n",
    "noisy_img = np.reshape(noisy_x.to(\"cpu\").data.numpy(), (28, 28))\n",
    "recovered_img = np.reshape(recovered_x.to(\"cpu\").data.numpy(), (28, 28))\n",
    "\n",
    "# 원본 사진\n",
    "a[0].set_title('Original')\n",
    "a[0].imshow(original_img, cmap='gray')\n",
    "\n",
    "# 오염된 원본 사진\n",
    "a[1].set_title('Noisy')\n",
    "a[1].imshow(noisy_img, cmap='gray')\n",
    "\n",
    "# 복원된 사진\n",
    "a[2].set_title('Recovered')\n",
    "a[2].imshow(recovered_img, cmap='gray')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3ef048",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
